{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n\n!pip install unsloth # install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git # Also get the latest version Unsloth!","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:41:50.663656Z","iopub.execute_input":"2025-05-08T17:41:50.663949Z","iopub.status.idle":"2025-05-08T17:44:35.062205Z","shell.execute_reply.started":"2025-05-08T17:41:50.663924Z","shell.execute_reply":"2025-05-08T17:44:35.061052Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Modules for fine-tuning\nfrom unsloth import FastLanguageModel\nimport torch # Import PyTorch\nfrom trl import SFTTrainer # Trainer for supervised fine-tuning (SFT)\nfrom unsloth import is_bfloat16_supported # Checks if the hardware supports bfloat16 precision\n# Hugging Face modules\nfrom huggingface_hub import login # Lets you login to API\nfrom transformers import TrainingArguments # Defines training hyperparameters\nfrom datasets import load_dataset # Lets you load fine-tuning datasets\n# Import weights and biases\nimport wandb\n# Import kaggle secrets\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:44:35.063522Z","iopub.execute_input":"2025-05-08T17:44:35.063747Z","iopub.status.idle":"2025-05-08T17:45:02.570839Z","shell.execute_reply.started":"2025-05-08T17:44:35.063727Z","shell.execute_reply":"2025-05-08T17:45:02.570196Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Initialize Hugging Face & WnB tokens\nuser_secrets = UserSecretsClient() # from kaggle_secrets import UserSecretsClient\nhugging_face_token = user_secrets.get_secret(\"HuggingfaceAPI\")\nwnb_token = user_secrets.get_secret(\"w&b\")\n\n# Login to Hugging Face\nlogin(hugging_face_token) # from huggingface_hub import login\n\n# Login to WnB\nwandb.login(key=wnb_token) # import wandb\nrun = wandb.init(\n    project='Fine-tune-DeepSeek-R1-Distill-Qwen-7B', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:45:02.571971Z","iopub.execute_input":"2025-05-08T17:45:02.572233Z","iopub.status.idle":"2025-05-08T17:45:15.910983Z","shell.execute_reply.started":"2025-05-08T17:45:02.572211Z","shell.execute_reply":"2025-05-08T17:45:15.910380Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mali408mehmood\u001b[0m (\u001b[33mali408mehmood-ghulam-ishaq-khan-institute-of-engineering\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250508_174509-vvf2ejx9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ali408mehmood-ghulam-ishaq-khan-institute-of-engineering/Fine-tune-DeepSeek-R1-Distill-Qwen-7B/runs/vvf2ejx9' target=\"_blank\">glad-thunder-2</a></strong> to <a href='https://wandb.ai/ali408mehmood-ghulam-ishaq-khan-institute-of-engineering/Fine-tune-DeepSeek-R1-Distill-Qwen-7B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ali408mehmood-ghulam-ishaq-khan-institute-of-engineering/Fine-tune-DeepSeek-R1-Distill-Qwen-7B' target=\"_blank\">https://wandb.ai/ali408mehmood-ghulam-ishaq-khan-institute-of-engineering/Fine-tune-DeepSeek-R1-Distill-Qwen-7B</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ali408mehmood-ghulam-ishaq-khan-institute-of-engineering/Fine-tune-DeepSeek-R1-Distill-Qwen-7B/runs/vvf2ejx9' target=\"_blank\">https://wandb.ai/ali408mehmood-ghulam-ishaq-khan-institute-of-engineering/Fine-tune-DeepSeek-R1-Distill-Qwen-7B/runs/vvf2ejx9</a>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Set parameters\nmax_seq_length = 2048 # Define the maximum sequence length a model can handle (i.e. how many tokens can be processed at once)\ndtype = None # Set to default \nload_in_4bit = True # Enables 4 bit quantization — a memory saving optimization \n\n# Load the DeepSeek R1 model and tokenizer using unsloth — imported using: from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/DeepSeek-R1-Distill-Qwen-7B\",  # Load the pre-trained DeepSeek R1 model (8B parameter version)\n    max_seq_length=max_seq_length, # Ensure the model can process up to 2048 tokens at once\n    dtype=dtype, # Use the default data type (e.g., FP16 or BF16 depending on hardware support)\n    load_in_4bit=load_in_4bit, # Load the model in 4-bit quantization to save memory\n    token=hugging_face_token, # Use hugging face token\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:46:02.753678Z","iopub.execute_input":"2025-05-08T17:46:02.754001Z","iopub.status.idle":"2025-05-08T17:47:48.918818Z","shell.execute_reply.started":"2025-05-08T17:46:02.753975Z","shell.execute_reply":"2025-05-08T17:47:48.918174Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.4.8: Fast Qwen2 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 6.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/100k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68829aa221b14ae59fa759d8071a3dbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0957a01b73cd421bbe45ed69f108de6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"595261645aaa453f9ab6abb511028aa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2492a9a4988c4cbebd770a89d6d03a0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd4a13a6473b417482c49314df8b8799"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/6.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bb1b14ad70b4064b42df82ef8aebc44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c8de85f9ca54d2287c4c092b6dc0430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cb4edaf82d64c9fb2c20ef983217f11"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Define a system prompt under prompt_style \nprompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\n{}\n\n### Response:\n<think>{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:47:54.342899Z","iopub.execute_input":"2025-05-08T17:47:54.343241Z","iopub.status.idle":"2025-05-08T17:47:54.347824Z","shell.execute_reply.started":"2025-05-08T17:47:54.343213Z","shell.execute_reply":"2025-05-08T17:47:54.346969Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Creating a test medical question for inference\nquestion = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or \n              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, \n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n\n# Enable optimized inference mode for Unsloth models (improves speed and efficiency)\nFastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n\n# Format the question using the structured prompt (`prompt_style`) and tokenize it\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")  # Convert input to PyTorch tensor & move to GPU\n\n# Generate a response using the model\noutputs = model.generate(\n    input_ids=inputs.input_ids, # Tokenized input question\n    attention_mask=inputs.attention_mask, # Attention mask to handle padding\n    max_new_tokens=1200, # Limit response length to 1200 tokens (to prevent excessive output)\n    use_cache=True, # Enable caching for faster inference\n)\n\n# Decode the generated output tokens into human-readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the relevant response part (after \"### Response:\")\nprint(response[0].split(\"### Response:\")[1])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:47:55.209471Z","iopub.execute_input":"2025-05-08T17:47:55.209768Z","iopub.status.idle":"2025-05-08T17:48:35.604352Z","shell.execute_reply.started":"2025-05-08T17:47:55.209743Z","shell.execute_reply":"2025-05-08T17:48:35.603372Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I'm trying to figure out what a 61-year-old woman with involuntary urine loss during activities like coughing or sneezing would show on a cystometry, especially considering she doesn't have leakage at night. Let me break this down step by step.\n\nFirst, I know that involuntary urination during certain activities is often related to the lower urinary tract, particularly the detrusor muscle. The detrusor is the muscle in the lower part of the bladder that helps push urine out when you need to. If it's not working properly, you might have trouble controlling urination, which can cause leakage during activities that require straining, like coughing or sneezing.\n\nThe question mentions a gynecological exam and a Q-tip test. I'm not entirely sure what a Q-tip test is, but I think it's a type of diagnostic test used in urology. Maybe it's similar to a dipstick test or a POC (point-of-care) test where a swab is taken to check for bacteria or other substances. But in this case, since she's not having leakage at night, perhaps the Q-tip test isn't showing any signs of infection or other issues.\n\nNow, the main question is about what a cystometry would show. Cystometry is a diagnostic test where a catheter is inserted into the bladder to measure the volume of urine that comes out in response to a pressure change. It's used to assess the residual volume in the bladder and the detrusor muscle function. \n\nIf there's no leakage at night, that suggests that during rest, the bladder is empty and the detrusor isn't contracting strongly enough to hold it. But during activities that strain the bladder, the detrusor might not be able to contract properly, leading to involuntary leakage.\n\nSo, during the cystometry, if the residual volume is low, that would mean that the bladder doesn't hold much urine. This could indicate a weak detrusor because a strong detrusor would help hold more urine until it's ready to be expelled. \n\nAdditionally, if the detrusor is not contracting effectively during the tests, the cystogram (the graph produced by cystometry) might show reduced detrusor contractions. This would be consistent with a diagnosis of detrusor dysfunction, which could be due to a condition like interstitial cystitis (IC), although IC is more commonly associated with chronic symptoms. Alternatively, it could be a temporary issue related to other factors, like recent trauma or a procedure, but since there's no mention of that, it's more likely a functional issue.\n\nPutting it all together, a low residual volume and reduced detrusor contractions on cystometry would suggest that the detrusor isn't working as effectively as it should, which explains the involuntary urination during straining activities. The absence of leakage at night supports the idea that the problem is related to the detrusor muscle function rather than the bladder itself holding urine.\n</think>\n\nThe 61-year-old woman presenting with involuntary urination during straining activities but without nighttime leakage suggests a potential issue with the detrusor muscle. Cystometry, a diagnostic tool that measures bladder volume and detrusor function, would reveal the following:\n\n1. **Low Residual Volume**: The absence of leakage at night indicates that the bladder does not hold significant urine volume. This low residual volume suggests that the detrusor muscle may not be strong enough to hold the bladder effectively, which is a common issue in conditions like interstitial cystitis.\n\n2. **Reduced Detrusor Contractions**: During the cystometry procedure, if the detrusor does not contract sufficiently, the cystogram (the graphical output of the test) would show diminished detrusor activity. This reduced contraction is consistent with detrusor dysfunction, making it difficult to hold urine until it is ready to be expelled.\n\nIn conclusion, the combination of low residual volume and reduced detrusor contractions on the cystogram supports the diagnosis of detrusor dysfunction, likely impacting her ability to control urination during straining activities.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Updated training prompt style to add </think> tag \ntrain_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\n{}\n\n### Response:\n<think>\n{}\n</think>\n{}\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:48:44.529593Z","iopub.execute_input":"2025-05-08T17:48:44.529937Z","iopub.status.idle":"2025-05-08T17:48:44.535394Z","shell.execute_reply.started":"2025-05-08T17:48:44.529909Z","shell.execute_reply":"2025-05-08T17:48:44.534372Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Download the dataset using Hugging Face — function imported using from datasets import load_dataset\ndataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\",\"en\", split = \"train[0:500]\",trust_remote_code=True) # Keep only first 500 rows\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:48:45.584699Z","iopub.execute_input":"2025-05-08T17:48:45.584974Z","iopub.status.idle":"2025-05-08T17:48:48.908609Z","shell.execute_reply.started":"2025-05-08T17:48:45.584954Z","shell.execute_reply":"2025-05-08T17:48:48.907931Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"326538da40fe40de9edc436235ae80ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medical_o1_sft.json:   0%|          | 0.00/58.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e83e7f254477482ea0427d95fde62e62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/19704 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b2814ccf1114b66be4987d2ba62d672"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Question', 'Complex_CoT', 'Response'],\n    num_rows: 500\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Show an entry from the dataset\ndataset[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:48:48.909754Z","iopub.execute_input":"2025-05-08T17:48:48.909994Z","iopub.status.idle":"2025-05-08T17:48:48.916584Z","shell.execute_reply.started":"2025-05-08T17:48:48.909971Z","shell.execute_reply":"2025-05-08T17:48:48.915907Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'Question': 'A 33-year-old woman is brought to the emergency department 15 minutes after being stabbed in the chest with a screwdriver. Given her vital signs of pulse 110/min, respirations 22/min, and blood pressure 90/65 mm Hg, along with the presence of a 5-cm deep stab wound at the upper border of the 8th rib in the left midaxillary line, which anatomical structure in her chest is most likely to be injured?',\n 'Complex_CoT': \"Okay, let's figure out what's going on here. A woman comes in with a stab wound from a screwdriver. It's in her chest, upper border of the 8th rib, left side, kind of around the midaxillary line. First thought, that's pretty close to where the lung sits, right?\\n\\nLet's talk about location first. This spot is along the left side of her body. Above the 8th rib, like that, is where a lot of important stuff lives, like the bottom part of the left lung, possibly the diaphragm too, especially considering how deep the screwdriver went.\\n\\nThe wound is 5 cm deep. That sounds pretty deep. I mean, it could definitely reach down to the lung tissue or maybe the diaphragm. Given that it's midaxillary, we're in the territory where the lower lobe of the left lung hangs out. It's also possible there's some intersection with where the diaphragm begins, but the lung feels more probable somehow.\\n\\nNow, her vitals are concerning: elevated heart rate and low blood pressure. This is serious. My gut says that this kind of vital sign picture could mean something like pneumothorax or maybe hemothorax. Both can happen if the lung gets punctured, and they can make the blood pressure drop and the heart rate skyrocket since she's obviously distressed.\\n\\nSo, putting it all together, the most obvious culprit is the lower lobe of the left lung. The wound's depth and her condition point that way. And, yeah, this adds up with pneumothorax or maybe blood collecting in the chest—the kind of stuff that can really mess with breathing and circulation.\\n\\nAlright, with this in mind, it sure seems like the lung is the most likely thing that got hurt here. Makes sense given the situation, where the wound is, considering her symptoms, and the whole setup.\",\n 'Response': 'In this scenario, the most likely anatomical structure to be injured is the lower lobe of the left lung. The location of the stab wound—at the upper border of the 8th rib in the left midaxillary line—indicates proximity to the lower lobe of the lung. The depth of the wound (5 cm) suggests it is sufficient to reach lung tissue. Her vital signs of elevated heart rate and low blood pressure could signal complications like a pneumothorax or hemothorax, common consequences of lung trauma that would result from a penetrating injury in this area. Given these considerations, the lower lobe of the left lung is the most probable structure injured.'}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# We need to format the dataset to fit our prompt training style \nEOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which the model when to stop generating text during training\nEOS_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:49:08.566764Z","iopub.execute_input":"2025-05-08T17:49:08.567071Z","iopub.status.idle":"2025-05-08T17:49:08.573476Z","shell.execute_reply.started":"2025-05-08T17:49:08.567046Z","shell.execute_reply":"2025-05-08T17:49:08.572539Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'<｜end▁of▁sentence｜>'"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Define formatting prompt function\ndef formatting_prompts_func(examples):  # Takes a batch of dataset examples as input\n    inputs = examples[\"Question\"]       # Extracts the medical question from the dataset\n    cots = examples[\"Complex_CoT\"]      # Extracts the chain-of-thought reasoning (logical step-by-step explanation)\n    outputs = examples[\"Response\"]      # Extracts the final model-generated response (answer)\n    \n    texts = []  # Initializes an empty list to store the formatted prompts\n    \n    # Iterate over the dataset, formatting each question, reasoning step, and response\n    for input, cot, output in zip(inputs, cots, outputs):  \n        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN  # Insert values into prompt template & append EOS token\n        texts.append(text)  # Add the formatted text to the list\n\n    return {\n        \"text\": texts,  # Return the newly formatted dataset with a \"text\" column containing structured prompts\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:49:09.117803Z","iopub.execute_input":"2025-05-08T17:49:09.118230Z","iopub.status.idle":"2025-05-08T17:49:09.125328Z","shell.execute_reply.started":"2025-05-08T17:49:09.118194Z","shell.execute_reply":"2025-05-08T17:49:09.124289Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Update dataset formatting\ndataset_finetune = dataset.map(formatting_prompts_func, batched = True)\ndataset_finetune[\"text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:49:10.111514Z","iopub.execute_input":"2025-05-08T17:49:10.112020Z","iopub.status.idle":"2025-05-08T17:49:10.164338Z","shell.execute_reply.started":"2025-05-08T17:49:10.111971Z","shell.execute_reply":"2025-05-08T17:49:10.163513Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30d31078e89d4f06b6413698d0d4e636"}},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"\"Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \\nPlease answer the following medical question. \\n\\n### Question:\\nGiven the symptoms of sudden weakness in the left arm and leg, recent long-distance travel, and the presence of swollen and tender right lower leg, what specific cardiac abnormality is most likely to be found upon further evaluation that could explain these findings?\\n\\n### Response:\\n<think>\\nOkay, let's see what's going on here. We've got sudden weakness in the person's left arm and leg - and that screams something neuro-related, maybe a stroke?\\n\\nBut wait, there's more. The right lower leg is swollen and tender, which is like waving a big flag for deep vein thrombosis, especially after a long flight or sitting around a lot.\\n\\nSo, now I'm thinking, how could a clot in the leg end up causing issues like weakness or stroke symptoms?\\n\\nOh, right! There's this thing called a paradoxical embolism. It can happen if there's some kind of short circuit in the heart - like a hole that shouldn't be there.\\n\\nLet's put this together: if a blood clot from the leg somehow travels to the left side of the heart, it could shoot off to the brain and cause that sudden weakness by blocking blood flow there.\\n\\nHmm, but how would the clot get from the right side of the heart to the left without going through the lungs and getting filtered out?\\n\\nHere's where our cardiac anomaly comes in: a patent foramen ovale or PFO. That's like a sneaky little shortcut in the heart between the right and left atria.\\n\\nAnd it's actually pretty common, found in about a quarter of adults, which definitely makes it the top suspect here.\\n\\nSo with all these pieces - long travel, leg clot, sudden weakness - a PFO fits the bill perfectly, letting a clot cross over and cause all this.\\n\\nEverything fits together pretty neatly, so I'd bet PFO is the heart issue waiting to be discovered. Yeah, that really clicks into place!\\n</think>\\nThe specific cardiac abnormality most likely to be found in this scenario is a patent foramen ovale (PFO). This condition could allow a blood clot from the venous system, such as one from a deep vein thrombosis in the leg, to bypass the lungs and pass directly into the arterial circulation. This can occur when the clot moves from the right atrium to the left atrium through the PFO. Once in the arterial system, the clot can travel to the brain, potentially causing an embolic stroke, which would explain the sudden weakness in the left arm and leg. The connection between the recent travel, which increases the risk of deep vein thrombosis, and the neurological symptoms suggests the presence of a PFO facilitating a paradoxical embolism.<｜end▁of▁sentence｜>\""},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Apply LoRA (Low-Rank Adaptation) fine-tuning to the model \nmodel_lora = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  # LoRA rank: Determines the size of the trainable adapters (higher = more parameters, lower = more efficiency)\n    target_modules=[  # List of transformer layers where LoRA adapters will be applied\n        \"q_proj\",   # Query projection in the self-attention mechanism\n        \"k_proj\",   # Key projection in the self-attention mechanism\n        \"v_proj\",   # Value projection in the self-attention mechanism\n        \"o_proj\",   # Output projection from the attention layer\n        \"gate_proj\",  # Used in feed-forward layers (MLP)\n        \"up_proj\",    # Part of the transformer’s feed-forward network (FFN)\n        \"down_proj\",  # Another part of the transformer’s FFN\n    ],\n    lora_alpha=16,  # Scaling factor for LoRA updates (higher values allow more influence from LoRA layers)\n    lora_dropout=0,  # Dropout rate for LoRA layers (0 means no dropout, full retention of information)\n    bias=\"none\",  # Specifies whether LoRA layers should learn bias terms (setting to \"none\" saves memory)\n    use_gradient_checkpointing=\"unsloth\",  # Saves memory by recomputing activations instead of storing them (recommended for long-context fine-tuning)\n    random_state=3407,  # Sets a seed for reproducibility, ensuring the same fine-tuning behavior across runs\n    use_rslora=False,  # Whether to use Rank-Stabilized LoRA (disabled here, meaning fixed-rank LoRA is used)\n    loftq_config=None,  # Low-bit Fine-Tuning Quantization (LoFTQ) is disabled in this configuration\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:49:13.355536Z","iopub.execute_input":"2025-05-08T17:49:13.355840Z","iopub.status.idle":"2025-05-08T17:49:19.849710Z","shell.execute_reply.started":"2025-05-08T17:49:13.355816Z","shell.execute_reply":"2025-05-08T17:49:19.849046Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.4.8 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Initialize the fine-tuning trainer — Imported using from trl import SFTTrainer\ntrainer = SFTTrainer(\n    model=model_lora,  # The model to be fine-tuned\n    tokenizer=tokenizer,  # Tokenizer to process text inputs\n    train_dataset=dataset_finetune,  # Dataset used for training\n    dataset_text_field=\"text\",  # Specifies which field in the dataset contains training text\n    max_seq_length=max_seq_length,  # Defines the maximum sequence length for inputs\n    dataset_num_proc=2,  # Uses 2 CPU threads to speed up data preprocessing\n\n    # Define training arguments\n    args=TrainingArguments(\n        per_device_train_batch_size=2,  # Number of examples processed per device (GPU) at a time\n        gradient_accumulation_steps=4,  # Accumulate gradients over 4 steps before updating weights\n        num_train_epochs=3, # Full fine-tuning run\n        warmup_steps=5,  # Gradually increases learning rate for the first 5 steps\n        max_steps=70,  # Limits training to 60 steps (useful for debugging; increase for full fine-tuning)\n        learning_rate=2e-4,  # Learning rate for weight updates (tuned for LoRA fine-tuning)\n        fp16=not is_bfloat16_supported(),  # Use FP16 (if BF16 is not supported) to speed up training\n        bf16=is_bfloat16_supported(),  # Use BF16 if supported (better numerical stability on newer GPUs)\n        logging_steps=10,  # Logs training progress every 10 steps\n        optim=\"adamw_8bit\",  # Uses memory-efficient AdamW optimizer in 8-bit mode\n        weight_decay=0.01,  # Regularization to prevent overfitting\n        lr_scheduler_type=\"linear\",  # Uses a linear learning rate schedule\n        seed=3407,  # Sets a fixed seed for reproducibility\n        output_dir=\"outputs\",  # Directory where fine-tuned model checkpoints will be saved\n    ),\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:49:26.608070Z","iopub.execute_input":"2025-05-08T17:49:26.608410Z","iopub.status.idle":"2025-05-08T17:49:28.944028Z","shell.execute_reply.started":"2025-05-08T17:49:26.608384Z","shell.execute_reply":"2025-05-08T17:49:28.943085Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd48b7795b434e2bb98a1e32f4525d5b"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Start the fine-tuning process\ntrainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:49:34.204239Z","iopub.execute_input":"2025-05-08T17:49:34.204533Z","iopub.status.idle":"2025-05-08T18:36:51.594007Z","shell.execute_reply.started":"2025-05-08T17:49:34.204509Z","shell.execute_reply":"2025-05-08T18:36:51.593377Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 500 | Num Epochs = 2 | Total steps = 70\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n \"-____-\"     Trainable parameters = 40,370,176/7,000,000,000 (0.58% trained)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [70/70 46:26, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.170300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.625500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.584400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.544400</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.588500</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.561300</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.495000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Save the fine-tuned model\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:37:00.168304Z","iopub.execute_input":"2025-05-08T18:37:00.168732Z","iopub.status.idle":"2025-05-08T18:37:01.795205Z","shell.execute_reply.started":"2025-05-08T18:37:00.168693Z","shell.execute_reply":"2025-05-08T18:37:01.794535Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▃▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>█▂▁▂▂▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▃▂▁</td></tr><tr><td>train/loss</td><td>█▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>1.8544663694893056e+16</td></tr><tr><td>train/epoch</td><td>1.112</td></tr><tr><td>train/global_step</td><td>70</td></tr><tr><td>train/grad_norm</td><td>0.14655</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.495</td></tr><tr><td>train_loss</td><td>1.65277</td></tr><tr><td>train_runtime</td><td>2835.1703</td></tr><tr><td>train_samples_per_second</td><td>0.198</td></tr><tr><td>train_steps_per_second</td><td>0.025</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">glad-thunder-2</strong> at: <a href='https://wandb.ai/ali408mehmood-ghulam-ishaq-khan-institute-of-engineering/Fine-tune-DeepSeek-R1-Distill-Qwen-7B/runs/vvf2ejx9' target=\"_blank\">https://wandb.ai/ali408mehmood-ghulam-ishaq-khan-institute-of-engineering/Fine-tune-DeepSeek-R1-Distill-Qwen-7B/runs/vvf2ejx9</a><br> View project at: <a href='https://wandb.ai/ali408mehmood-ghulam-ishaq-khan-institute-of-engineering/Fine-tune-DeepSeek-R1-Distill-Qwen-7B' target=\"_blank\">https://wandb.ai/ali408mehmood-ghulam-ishaq-khan-institute-of-engineering/Fine-tune-DeepSeek-R1-Distill-Qwen-7B</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250508_174509-vvf2ejx9/logs</code>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer\n\ndef compute_perplexity(model, tokenizer, text):\n    \"\"\"\n    Computes perplexity (PPL) of a given text using a fine-tuned LoRA model.\n    \"\"\"\n    model.eval()  # Set model to evaluation mode\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model.to(device)\n\n    # Tokenize input text\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n    input_ids = inputs.input_ids.to(device)\n    attention_mask = inputs.attention_mask.to(device)\n\n    with torch.no_grad():  # Disable gradient computation\n        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n        loss = outputs.loss  # Get cross-entropy loss\n\n    # Compute perplexity\n    perplexity = torch.exp(loss).item()\n    return perplexity\n\n# Example usage\ntext_sample = \"\"\"A 59-year-old man presents with a fever, chills, night sweats, and generalized fatigue, \n              and is found to have a 12 mm vegetation on the aortic valve. Blood cultures indicate gram-positive, catalase-negative, \n              gamma-hemolytic cocci in chains that do not grow in a 6.5% NaCl medium. \n              What is the most likely predisposing factor for this patient's condition?\"\"\"\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/outputs/checkpoint-70\")  # Use the same tokenizer as during training\nppl = compute_perplexity(model_lora, tokenizer, text_sample)\n\nprint(f\"Perplexity: {ppl:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:37:05.668952Z","iopub.execute_input":"2025-05-08T18:37:05.669272Z","iopub.status.idle":"2025-05-08T18:37:06.474228Z","shell.execute_reply.started":"2025-05-08T18:37:05.669246Z","shell.execute_reply":"2025-05-08T18:37:06.473307Z"}},"outputs":[{"name":"stdout","text":"Perplexity: 14.33\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# -------------------------------\n# Required installations (run once)\n# -------------------------------\n!pip install rouge-score seqeval spacy\n!python -m spacy download en_core_web_sm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:37:44.096895Z","iopub.execute_input":"2025-05-08T18:37:44.097235Z","iopub.status.idle":"2025-05-08T18:38:03.160143Z","shell.execute_reply.started":"2025-05-08T18:37:44.097209Z","shell.execute_reply":"2025-05-08T18:38:03.159000Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge-score) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge-score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nBuilding wheels for collected packages: rouge-score, seqeval\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=671ec3267fb9b167b00957019a095c14c126cf00b17a994896719163be700f81\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=d66cecbb65f6669d0d933ebaac430fc0228d417aaa39116411551658546886f1\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built rouge-score seqeval\nInstalling collected packages: seqeval, rouge-score\nSuccessfully installed rouge-score-0.1.2 seqeval-1.2.2\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.13.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"question = \"\"\"A 33-year-old woman is brought to the emergency department 15 minutes after being stabbed in the chest with a screwdriver. Given her vital signs of pulse 110/min, respirations 22/min, and blood pressure 90/65 mm Hg, along with the presence of a 5-cm deep stab wound at the upper border of the 8th rib in the left midaxillary line, which anatomical structure in her chest is most likely to be injured?\"\"\"\n\n# Tokenize the input question with a specific prompt format and move it to the GPU\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\n# Generate a response using LoRA fine-tuned model with specific parameters\noutputs = model_lora.generate(\n    input_ids=inputs.input_ids,          # Tokenized input IDs\n    attention_mask=inputs.attention_mask, # Attention mask for padding handling\n    max_new_tokens=1200,                  # Maximum length for generated response\n    use_cache=True,                        # Enable cache for efficient generation\n)\n\n# Decode the generated response from tokenized format to readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the model's response part after \"### Response:\"\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:38:03.161786Z","iopub.execute_input":"2025-05-08T18:38:03.162136Z","iopub.status.idle":"2025-05-08T18:38:31.163885Z","shell.execute_reply.started":"2025-05-08T18:38:03.162087Z","shell.execute_reply":"2025-05-08T18:38:31.163092Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nAlright, let's think about this situation. We have a 33-year-old woman who is brought to the emergency department just 15 minutes after being stabbed in the chest with a screwdriver. Her vital signs show a pulse of 110/min, respirations of 22/min, and a blood pressure of 90/65 mm Hg. There's also a 5-cm deep stab wound at the upper border of the 8th rib in the left midaxillary line.\n\nOkay, so first, let's think about what we're dealing with here. The fact that she's in the emergency department 15 minutes after the stabbing suggests that she's likely experiencing some significant injury. The wound is at the upper border of the 8th rib, which is pretty high up in the chest. That's interesting because it suggests that the wound might have caused some compression on the lung or heart.\n\nNow, let's think about the vital signs. Her pulse is 110/min, which is a bit high but not critically concerning yet. Her respirations are at 22/min, which is a bit rapid but not too bad. Blood pressure is low at 90/65 mm Hg, which means her heart is not getting enough blood to function properly.\n\nConsidering all this, the most concerning part is the blood pressure. At 90/65 mm Hg, her heart is not getting enough blood. This could be because of compression from the wound in the chest, affecting the heart's ability to pump blood properly.\n\nSo, what's the anatomy here? The 8th rib is pretty high up, and the wound is at its upper border. If there's a stab wound there, it could be compressing the ribcage, which is responsible for protecting the heart and lungs. That's why the blood pressure is dropping and the heart rate is a bit high.\n\nPutting this all together, it seems like the ribcage is the most likely structure being injured due to the stab wound. This makes sense because the ribcage is crucial for protecting vital organs and ensuring they function properly during medical emergencies like this.\n</think>\nThe stab wound is located at the upper border of the 8th rib in the left midaxillary line. Given the patient's vital signs, which indicate a potential heart and lung compromise, it is most likely the ribcage that is being injured due to the wound's compression. This is because the ribcage protects the heart and lungs, and any significant compression could lead to reduced blood flow to these vital organs.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"final_answer = \"\"\"The stab wound is located at the upper border of the 8th rib in the left midaxillary line. Given the patient's vital signs, which indicate a potential heart and lung compromise, it is most likely the ribcage that is being injured due to the wound's compression. This is because the ribcage protects the heart and lungs, and any significant compression could lead to reduced blood flow to these vital organs.\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:38:44.283975Z","iopub.execute_input":"2025-05-08T18:38:44.284312Z","iopub.status.idle":"2025-05-08T18:38:44.288109Z","shell.execute_reply.started":"2025-05-08T18:38:44.284280Z","shell.execute_reply":"2025-05-08T18:38:44.287412Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"\nimport re\nfrom rouge_score import rouge_scorer\nimport spacy\nfrom seqeval.metrics import classification_report\n\n# Load spaCy NER model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# === Sample input ===\nquestion = \"\"\"A 33-year-old woman is brought to the emergency department 15 minutes after being stabbed in the chest with a screwdriver. Given her vital signs of pulse 110/min, respirations 22/min, and blood pressure 90/65 mm Hg, along with the presence of a 5-cm deep stab wound at the upper border of the 8th rib in the left midaxillary line, which anatomical structure in her chest is most likely to be injured?\"\"\"\n\nreference_answer = \"\"\" In this scenario, the most likely anatomical structure to be injured is the lower lobe of the left lung. The location of the stab wound—at the upper border of the 8th rib in the left midaxillary line—indicates proximity to the lower lobe of the lung. The depth of the wound (5 cm) suggests it is sufficient to reach lung tissue. Her vital signs of elevated heart rate and low blood pressure could signal complications like a pneumothorax or hemothorax, common consequences of lung trauma that would result from a penetrating injury in this area. Given these considerations, the lower lobe of the left lung is the most probable structure injured.\"\"\"\n\n# === ROUGE Score ===\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\nscores = scorer.score(reference_answer, final_answer)\n\nprint(\"📊 ROUGE Scores:\")\nfor k, v in scores.items():\n    print(f\"{k}: Precision: {v.precision:.4f}, Recall: {v.recall:.4f}, F1: {v.fmeasure:.4f}\")\n\n# === NER Comparison ===\ndef extract_ner_entity_types(text):\n    doc = nlp(text)\n    return set(ent.label_ for ent in doc.ents)\n\ntrue_ner = extract_ner_entity_types(reference_answer)\npred_ner = extract_ner_entity_types(final_answer)\n\nprint(\"\\n🧠 NER Entity Type Comparison:\")\nprint(\"True NER Types:\", true_ner)\nprint(\"Predicted NER Types:\", pred_ner)\nprint(\"Common NER Types:\", true_ner & pred_ner)\nprint(\"Missing NER Types:\", true_ner - pred_ner)\nprint(\"Extra NER Types:\", pred_ner - true_ner)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:38:53.115686Z","iopub.execute_input":"2025-05-08T18:38:53.115989Z","iopub.status.idle":"2025-05-08T18:38:54.894086Z","shell.execute_reply.started":"2025-05-08T18:38:53.115964Z","shell.execute_reply":"2025-05-08T18:38:54.893294Z"}},"outputs":[{"name":"stdout","text":"📊 ROUGE Scores:\nrouge1: Precision: 0.6667, Recall: 0.4286, F1: 0.5217\nrouge2: Precision: 0.2817, Recall: 0.1802, F1: 0.2198\nrougeL: Precision: 0.3750, Recall: 0.2411, F1: 0.2935\n\n🧠 NER Entity Type Comparison:\nTrue NER Types: {'QUANTITY', 'ORDINAL'}\nPredicted NER Types: {'ORDINAL'}\nCommon NER Types: {'ORDINAL'}\nMissing NER Types: {'QUANTITY'}\nExtra NER Types: set()\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}